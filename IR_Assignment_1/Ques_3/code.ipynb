{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to dataset\n",
    "path = r\"/home/sumit20136/IR_Assignment_1/Dataset\"\n",
    "\n",
    "#Changing the directory\n",
    "os.chdir(path)\n",
    "dictionary = {}\n",
    "relPath = \"/home/sumit20136/IR_Assignment_1/Ques_3\"\n",
    "indexPickle = \"/home/sumit20136/IR_Assignment_1/Ques_3/bigram_inverted_index.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(file_path):\n",
    "    with open(file_path,'r') as myFile:\n",
    "        qwe = myFile.read()\n",
    "        x = qwe.split()\n",
    "        for i in range(len(x)-1):\n",
    "            op = x[i]+\" \"+x[i+1]\n",
    "            if op in dictionary.keys():\n",
    "                if(file_path[len(file_path)-13:len(file_path)] not in dictionary[op]):\n",
    "                    dictionary[op].append(file_path[len(file_path)-13:len(file_path)])\n",
    "            else:\n",
    "                dictionary[op] = [file_path[len(file_path)-13:len(file_path)]]\n",
    "\n",
    "\n",
    "def remove_stop(s):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(s)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def remove_punc(s):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return remove_stop(s.translate(translator))\n",
    "\n",
    "\n",
    "def remove_space(s):\n",
    "    return remove_punc(\" \".join(s.split()))\n",
    "\n",
    "\n",
    "def lowercase(s):\n",
    "    return remove_space(s.lower())\n",
    "\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\"\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        check(file_path)\n",
    "\n",
    "\n",
    "def listToString(s):\n",
    "    s.sort()\n",
    "    return \" \".join(s)\n",
    "    \n",
    "\n",
    "def save_index(index, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(index, f)\n",
    "\n",
    "\n",
    "def load_index(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'note creep': ['cranfield1024', 'cranfield1017', 'cranfield1029', 'cranfield1018', 'cranfield1019', 'cranfield1021', 'cranfield1031', 'cranfield1035', 'cranfield1023', 'cranfield1020', 'cranfield1026', 'cranfield1027', 'cranfield1022', 'cranfield1028', 'cranfield1034', 'cranfield1030', 'cranfield1025'], 'creep buckling': ['cranfield1024', 'cranfield1016', 'cranfield1017', 'cranfield1029', 'cranfield1018', 'cranfield0950', 'cranfield1052', 'cranfield1019', 'cranfield1021', 'cranfield1031', 'cranfield1035', 'cranfield1013', 'cranfield1023', 'cranfield1020', 'cranfield1026', 'cranfield1027', 'cranfield1022', 'cranfield1015', 'cranfield1028', 'cranfield1034', 'cranfield0951', 'cranfield1012', 'cranfield1030', 'cranfield1025', 'cranfield1014'], 'buckling columns': ['cranfield1024', 'cranfield1017', 'cranfield1029', 'cranfield1018', 'cranfield1019', 'cranfield1021', 'cranfield1031', 'cranfield1035', 'cranfield1013', 'cranfield1023', 'cranfield1020', 'cranfield1026', 'cranfield1027', 'cranfield1022', 'cranfield0820', 'cranfield1028', 'cranfield1034', 'cranfield1120', 'cranfield1030', 'cranfield1025'], 'columns general': ['cranfield1024', 'cranfield1031', 'cranfield1030'], 'general dynamic': ['cranfield1024']}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "out = dict(itertools.islice(dictionary.items(), 5))\n",
    "print(str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index(dictionary, indexPickle)\n",
    "loadedDictionary = load_index(indexPickle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexPickle = \"/home/sumit20136/IR_Assignment_1/Ques_3/bigram_positional_inverted_index.pickle\"\n",
    "\n",
    "\n",
    "def build_positional_index():\n",
    "    index = {}\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\"\"):\n",
    "            file_path = f\"{path}\\{file}\"\n",
    "            with open(file, 'r') as f:\n",
    "                line_no = 0\n",
    "                for line in f:\n",
    "                    line_no += 1\n",
    "                    words = line.strip().split()\n",
    "                    for pos, word in enumerate(words):\n",
    "                        if word not in index:\n",
    "                            index[word] = {}\n",
    "                        if file not in index[word]:\n",
    "                            index[word][file] = []\n",
    "                        index[word][file].append(pos)  # Can remove line number\n",
    "    return index\n",
    "\n",
    "\n",
    "def save_index(index, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(index, f)\n",
    "\n",
    "\n",
    "def load_index(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_positional_index()\n",
    "save_index(index, indexPickle)\n",
    "loaded_index = load_index(indexPickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(loaded_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1 query\n",
      "Total number of occurences of word note creep is 17\n",
      "The files having the word was cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1034 cranfield1035\n",
      "\n",
      "Total number of occurences of word creep creep is 0\n",
      "\n",
      "Total number of occurences of word creep buckling is 25\n",
      "The files having the word was cranfield0950 cranfield0951 cranfield1012 cranfield1013 cranfield1014 cranfield1015 cranfield1016 cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1034 cranfield1035 cranfield1052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexPickle=\"/home/sumit20136/IR_Assignment_1/Ques_3/bigram_inverted_index.pickle\"\n",
    "loaded_index = load_index(indexPickle)\n",
    "n=int(input())\n",
    "for i in range(n):\n",
    "    print(f\"For {i+1} query\")\n",
    "    jh = input()\n",
    "    ggf = lowercase(jh)\n",
    "    \n",
    "    kk = list()\n",
    "    for i in range(len(ggf)-1):\n",
    "        ho = ggf[i]+\" \"+ggf[i+1]\n",
    "        kk.append(ho)\n",
    "    \n",
    "    for i in kk:\n",
    "        if i in dictionary.keys():\n",
    "            lpu = dictionary[i]\n",
    "            if len(lpu):\n",
    "                print(\"Number of documents retrieved for query 1 using bigram inverted index: \" + str(len(lpu)))\n",
    "                print(\"Names of documents retrieved for query 1 using bigram inverted index: \" + listToString(lpu))\n",
    "                print()\n",
    "        else:\n",
    "                print(\"Total number of occurences of word \"+ i + \" is \" + str(0))\n",
    "                # print(\"The files having the word was \" + ))\n",
    "                print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Positional Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1 query\n",
      "Total number of occurences of word note is 99\n",
      "The files having the word was cranfield0018 cranfield0019 cranfield0026 cranfield0028 cranfield0037 cranfield0043 cranfield0044 cranfield0046 cranfield0057 cranfield0087 cranfield0088 cranfield0090 cranfield0134 cranfield0138 cranfield0223 cranfield0285 cranfield0286 cranfield0293 cranfield0295 cranfield0298 cranfield0313 cranfield0316 cranfield0323 cranfield0324 cranfield0354 cranfield0359 cranfield0370 cranfield0371 cranfield0382 cranfield0388 cranfield0392 cranfield0393 cranfield0402 cranfield0439 cranfield0450 cranfield0480 cranfield0488 cranfield0506 cranfield0508 cranfield0521 cranfield0527 cranfield0528 cranfield0532 cranfield0534 cranfield0537 cranfield0539 cranfield0546 cranfield0548 cranfield0557 cranfield0581 cranfield0583 cranfield0606 cranfield0609 cranfield0614 cranfield0622 cranfield0633 cranfield0669 cranfield0689 cranfield0720 cranfield0751 cranfield0756 cranfield0768 cranfield0789 cranfield0798 cranfield0806 cranfield0855 cranfield0875 cranfield0904 cranfield0934 cranfield0939 cranfield0969 cranfield0983 cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1034 cranfield1035 cranfield1085 cranfield1086 cranfield1122 cranfield1142 cranfield1265 cranfield1299 cranfield1302 cranfield1310 cranfield1372 cranfield1393\n",
      "\n",
      "Total number of occurences of word creep is 34\n",
      "The files having the word was cranfield0550 cranfield0767 cranfield0833 cranfield0837 cranfield0866 cranfield0869 cranfield0870 cranfield0871 cranfield0950 cranfield0951 cranfield0952 cranfield1012 cranfield1013 cranfield1014 cranfield1015 cranfield1016 cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1034 cranfield1035 cranfield1052\n",
      "\n",
      "Total number of occurences of word creep is 34\n",
      "The files having the word was cranfield0550 cranfield0767 cranfield0833 cranfield0837 cranfield0866 cranfield0869 cranfield0870 cranfield0871 cranfield0950 cranfield0951 cranfield0952 cranfield1012 cranfield1013 cranfield1014 cranfield1015 cranfield1016 cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1034 cranfield1035 cranfield1052\n",
      "\n",
      "Total number of occurences of word buckling is 117\n",
      "The files having the word was cranfield0031 cranfield0400 cranfield0412 cranfield0419 cranfield0642 cranfield0658 cranfield0739 cranfield0740 cranfield0741 cranfield0743 cranfield0744 cranfield0760 cranfield0761 cranfield0763 cranfield0765 cranfield0766 cranfield0769 cranfield0820 cranfield0822 cranfield0823 cranfield0824 cranfield0825 cranfield0826 cranfield0827 cranfield0830 cranfield0831 cranfield0833 cranfield0838 cranfield0839 cranfield0843 cranfield0856 cranfield0858 cranfield0859 cranfield0885 cranfield0886 cranfield0887 cranfield0888 cranfield0889 cranfield0890 cranfield0891 cranfield0897 cranfield0898 cranfield0915 cranfield0926 cranfield0928 cranfield0929 cranfield0932 cranfield0935 cranfield0936 cranfield0937 cranfield0948 cranfield0950 cranfield0951 cranfield0956 cranfield0957 cranfield1012 cranfield1013 cranfield1014 cranfield1015 cranfield1016 cranfield1017 cranfield1018 cranfield1019 cranfield1020 cranfield1021 cranfield1022 cranfield1023 cranfield1024 cranfield1025 cranfield1026 cranfield1027 cranfield1028 cranfield1029 cranfield1030 cranfield1031 cranfield1032 cranfield1034 cranfield1035 cranfield1037 cranfield1048 cranfield1050 cranfield1051 cranfield1052 cranfield1053 cranfield1055 cranfield1067 cranfield1068 cranfield1070 cranfield1071 cranfield1116 cranfield1117 cranfield1119 cranfield1120 cranfield1121 cranfield1122 cranfield1123 cranfield1126 cranfield1127 cranfield1131 cranfield1132 cranfield1145 cranfield1146 cranfield1172 cranfield1173 cranfield1174 cranfield1176 cranfield1177 cranfield1178 cranfield1357 cranfield1358 cranfield1359 cranfield1362 cranfield1387 cranfield1392 cranfield1396 cranfield1399 cranfield1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexPickle=\"/home/sumit20136/IR_Assignment_1/Ques_3/bigram_positional_inverted_index.pickle\"\n",
    "loaded_index = load_index(indexPickle)\n",
    "n=int(input())\n",
    "for i in range(n):\n",
    "    print(f\"For {i+1} query\")\n",
    "    jh = input()\n",
    "    ggf = lowercase(jh)\n",
    "\n",
    "    # inputStr = \"note note creep and buckling\"\n",
    "    #ggf=[note,note,creep,buckling]\n",
    "    #kk=[note note, note creep, creep buckling]\n",
    "        \n",
    "        \n",
    "    for i in ggf:\n",
    "        if i in loaded_index.keys():\n",
    "            lpu = loaded_index[i]\n",
    "            if len(lpu):\n",
    "                print(\"Number of documents retrieved for query 1 using bigram inverted index: \" + str(len(lpu)))\n",
    "                print(\"Names of documents retrieved for query 1 using bigram inverted index: \" + listToString(list(lpu.keys())))\n",
    "                print()\n",
    "        else:\n",
    "                print(\"Number of documents retrieved for query 1 using bigram inverted index: \" + str(len(lpu)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumitsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8dbe7c57848b21e8ac285795094c75980909ef02a1be97b8abdf6e3ff2c5ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
